{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "LAYER1_NODE = 500\n",
    "BATCH_SIZE = 2000\n",
    "\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 3000\n",
    "MOVING_AVERAGE_DECAY = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现了前向传播算法，同时支持滑动平均算法\n",
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2) + avg_class.average(biases2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.int64, name='y-input')\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = mnist\n",
    "    x_train = np.array([x.flatten() for x in x_train])\n",
    "    x_test = np.array([x.flatten() for x in x_test])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "    \n",
    "#     print('x_train shape: {}, x_test shape: {}'.format(x_train.shape, x_test.shape) )\n",
    "#     print('y_train shape: {}, y_test shape: {}'.format(y_train.shape, y_test.shape))\n",
    "#     print('x_val shape: {}, y_val shape: {}'.format(x_val.shape, y_val.shape))\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        x_train.shape[0] / BATCH_SIZE,\n",
    "        LEARNING_RATE_DECAY\n",
    "    )\n",
    "    \n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    with tf.control_dependencies([train_step, variable_averages_op]):\n",
    "        # no_op(...): Does nothing. Only useful as a placeholder for control edges.\n",
    "        train_op = tf.no_op(name='train')\n",
    "    # 验证使用滑动平均模型的神经网络传播结果是否正确\n",
    "    # tf.argmax() 函数的第二个参数“1” 表示选取最大值操作仅在第一个维度中进行。\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), y_)\n",
    "    correct = tf.reduce_sum(tf.cast(correct_prediction, tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    batch_num = x_train.shape[0] // BATCH_SIZE\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        validate_feed = {\n",
    "            x: x_val,\n",
    "            y_: y_val\n",
    "        }\n",
    "    \n",
    "        test_feed = {x: x_test, y_: y_test}\n",
    "    \n",
    "        for i in progress_bar(range(TRAINING_STEPS)):\n",
    "            if i % 50 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                val_correct = sess.run(correct, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g correct is %g\" % (i, validate_acc, val_correct))\n",
    "            \n",
    "            for j in range(batch_num):\n",
    "                start = j * BATCH_SIZE\n",
    "                end = (j + 1) * BATCH_SIZE\n",
    "                xs, ys = x_train[start: end], y_train[start: end]\n",
    "                sess.run([train_op, global_step], feed_dict={x: xs, y_: ys})\n",
    "            \n",
    "        test_acc = sess.run(accuracy, feed_dict={x: x_test, y_: y_test})\n",
    "        print(\"After %d training step(s), test accuracy using average model is %g \" % (TRAINING_STEPS, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist.load_data('/home/ycli/code/tensorflow_notes/data/mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5955b011e044e5bb1e111c3081f505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5955b011e044e5bb1e111c3081f505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='0.00% [0/3000 00:00<00:00]')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training step(s), validation accuracy using average model is 0.114667 correct is 688\n",
      "After 50 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 100 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 150 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 200 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 250 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 300 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 350 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 400 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 450 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 500 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 550 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 600 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 650 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 700 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 750 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 800 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 850 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 900 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 950 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1000 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1050 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1100 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1150 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1200 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1250 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1300 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1350 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1400 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1450 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1500 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1550 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1600 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1650 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1700 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1750 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1800 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1850 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1900 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 1950 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2000 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2050 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2100 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2150 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2200 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2250 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2300 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2350 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2400 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2450 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2500 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2550 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2600 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2650 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2700 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2750 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2800 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2850 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2900 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 2950 training step(s), validation accuracy using average model is 0.104 correct is 624\n",
      "After 3000 training step(s), test accuracy using average model is 0.098 \n"
     ]
    }
   ],
   "source": [
    "train(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
